material {
    name : hbao,
    parameters : [
        {
            type : sampler2d,
            name : depth,
            precision: high
        },
        {
            type : bool,
            name : noise
        },
        {
            type : float4,
            name : resolution
        },
        {
            type : float,
            name : sampleRadius
        },
        {
            type : int,
            name : sampleDirections
        },
        {
            type : float,
            name : sampleSteps
        },
        {
            type : bool,
            name : useAttenuation
        },
        {
            type : float,
            name : attenuationScale
        },
        {
            type : float,
            name : angleBias
        },
        {
            type : float,
            name : noiseamount
        },
        {
            type : float,
            name : jitterAmount
        },
        {
            type : float,
            name : intensity
        }
    ],
    variables : [
         vertex
    ],
    domain : postprocess,
    depthWrite : false,
    depthCulling : true
}

vertex {
    void postProcessVertex(inout PostProcessVertexInputs postProcess) {
        postProcess.vertex.xy = postProcess.normalizedUV;
    }
}

fragment {

    highp float linearizeDepth(highp float depth) {
        // Our far plane is at infinity, which causes a division by zero below, which in turn
        // causes some issues on some GPU. We workaround it by replacing "infinity" by the closest
        // value representable in  a 24 bit depth buffer.
        const float preventDiv0 = -1.0 / 16777216.0;
        highp mat4 projection = getClipFromViewMatrix();
        highp float z = depth * 2.0 - 1.0; // depth in clip space
        return -projection[3].z / min(preventDiv0, z + projection[2].z);
    }

    highp float sampleDepthLinear(const vec2 uv) {
        return linearizeDepth(texture(materialParams_depth, uv, 0.0).r);
    }

    highp vec3 computeViewSpacePositionFromDepth(vec2 p, highp float linearDepth) {
        p = p * 2.0 - 1.0; // to clip space
        highp mat4 invProjection = getViewFromClipMatrix();
        p.x *= invProjection[0].x;
        p.y *= invProjection[1].y;
        return vec3(p * -linearDepth, linearDepth);
    }

    // compute normals using derivatives, which essentially results in half-resolution normals
    // this creates arifacts around geometry edges
    highp vec3 computeViewSpaceNormalNotNormalized(const highp vec3 position) {
        highp vec3 dpdx = dFdx(position);
        highp vec3 dpdy = dFdy(position);
        return cross(dpdx, dpdy);
    }

    // compute normals directly from the depth texture, resulting in full resolution normals
    highp vec3 computeViewSpaceNormalNotNormalized(const highp vec3 position, const vec2 uv) {
        vec2 uvdx = uv + vec2(materialParams.resolution.z, 0.0);
        vec2 uvdy = uv + vec2(0.0, materialParams.resolution.w);
        highp vec3 px = computeViewSpacePositionFromDepth(uvdx, sampleDepthLinear(uvdx));
        highp vec3 py = computeViewSpacePositionFromDepth(uvdy, sampleDepthLinear(uvdy));
        highp vec3 dpdx = px - position;
        highp vec3 dpdy = py - position;
        return cross(dpdx, dpdy);
    }

//THIS NEEDS TO MATCH YOUR CAMERA SETTINGS---------------------

const float fov = 30.0;//FoV
//-------------------------------------------------------------


//USER VARIABLES-----------------------------------------------
//const float intensity = 1.2;//Intensity of the AO effect
//const float sampleRadius = 9.0;//Radius of the AO, bigger values need more performance


//const float sampleDirections = 10.0;//Main sample count, affects performance heavily
//const float sampleSteps = 32.0;//SubSample count, sometimes higher values are faster


//const bool useAttenuation = false;//Applies attenuation to each AO sample, different values look better depending on your scene
//const float attenuationScale = 1.0;//Depth scale of the attenuation, different values look better depending on your scene


//const float angleBias = 0.2;//Brightens up the AO effect to reduce noise and artifacts


//const bool noise = false;//Use noise instead of pattern for sample dithering, much slower but more accurate
//const float noiseamount = 1.0;//Per-Pixel noise amount, bigger values need more performance
//const float jitterAmount = 1.0;//Per-Sample noise amount, bigger values need more performance

const float lumInfluence = 0.3;//Influence of the luminance on the AO effect

//-------------------------------------------------------------


    const float TWO_PI = 6.283185307;

    float rand(vec2 co, float2 size, bool noise)
    {
        if (noise) {
            return fract(sin(dot(co.xy, vec2(12.9898, 78.233)*3.0)) * 43758.5453);
        } else {
            return ((fract(1.0-co.s*(size.x/2.0))*0.3)+(fract(co.t*(size.y/2.0))*0.6))*2.0-1.0;
        }
    }

    vec2 rand2D(vec2 coord, float2 size, bool noise, float noiseamount)//generating noise/pattern texture for dithering
    {
        float noiseX = ((fract(1.0-coord.s*(size.x/2.0))*0.25)+(fract(coord.t*(size.y/2.0))*0.75))*2.0-1.0;
        float noiseY = ((fract(1.0-coord.s*(size.x/2.0))*0.75)+(fract(coord.t*(size.y/2.0))*0.25))*2.0-1.0;

        if (noise)
        {
            noiseX = clamp(fract(sin(dot(coord, vec2(12.9898, 78.233))) * 43758.5453), 0.0, 1.0)*2.0-1.0;
            noiseY = clamp(fract(sin(dot(coord, vec2(12.9898, 78.233)*2.0)) * 43758.5453), 0.0, 1.0)*2.0-1.0;
        }
        return vec2(noiseX, noiseY)*noiseamount;
    }

    void postProcess(inout PostProcessInputs postProcess) {
        highp vec2 uv = variable_vertex.xy; // interpolated to pixel center
        highp float depth = sampleDepthLinear(uv);

        vec2 texCoord = uv;

        mat4 viewProjectionInverseMatrix  = getViewFromClipMatrix();

        vec3 originVS = computeViewSpacePositionFromDepth(uv, depth);

        highp vec3 normalNotNormalized = computeViewSpaceNormalNotNormalized(originVS, uv);
        vec3 normalVS = normalize(normalNotNormalized);

        float radiusSS = 0.0;
        float radiusWS = 0.0;

        radiusSS = materialParams.sampleRadius;
        vec4 temp0 = viewProjectionInverseMatrix * vec4(0.0, 0.0, -1.0, 1.0);
        vec3 out0 = temp0.xyz;
        vec4 temp1 = viewProjectionInverseMatrix * vec4(radiusSS, 0.0, -1.0, 1.0);
        vec3 out1 = temp1.xyz;

        radiusWS = min(tan(radiusSS * fov * 0.0087266462597222) * originVS.z, length(out1 - out0));

        float theta = TWO_PI / float(materialParams.sampleDirections);
        float cosTheta = cos(theta);
        float sinTheta = sin(theta);

        mat2 deltaRotationMatrix = mat2(cosTheta, -sinTheta, sinTheta, cosTheta);
        vec2 deltaUV = vec2(1.0, 0.0) * (radiusSS / (float(materialParams.sampleDirections) * materialParams.sampleSteps + 1.0));

        vec2 sampleNoise = rand2D(texCoord, materialParams.resolution.xy, materialParams.noise, materialParams.noiseamount);
        mat2 rotationMatrix = mat2(sampleNoise.x, -sampleNoise.y,
        sampleNoise.y, sampleNoise.x);

        deltaUV = rotationMatrix * deltaUV;

        float occlusion = 0.0;
        float jitter = rand(texCoord, materialParams.resolution.xy, materialParams.noise) * materialParams.jitterAmount;

        for (int i = 0; i < materialParams.sampleDirections; i++) {
            deltaUV = deltaRotationMatrix * deltaUV;

            vec2 sampleDirUV = deltaUV;
            float oldAngle = materialParams.angleBias;

            for (int j = 0; j < materialParams.sampleDirections; j++) {
                vec2 sampleUV = texCoord + (jitter + float(j)) * sampleDirUV;

                highp float sampleDepth = sampleDepthLinear(sampleUV);
                vec3 sampleVS = computeViewSpacePositionFromDepth(sampleUV, sampleDepth);

                vec3 sampleDirVS = (sampleVS - originVS);

                float gamma = 1.570796326 - acos(dot(normalVS, normalize(sampleDirVS)));

                if (gamma > oldAngle) {
                    float value = sin(gamma) - sin(oldAngle);

                    if (materialParams.useAttenuation) {
                        float attenuation = clamp(1.0 - pow(length(sampleDirVS) / radiusWS * materialParams.attenuationScale, 2.0), 0.0, 1.0);
                        occlusion += attenuation * value;
                    } else {
                        occlusion += value;
                    }

                    oldAngle = gamma;
                }
            }
        }

        occlusion = 1.0 - occlusion / float(materialParams.sampleDirections);
        occlusion = clamp(pow(occlusion, 1.0 + materialParams.intensity), 0.0, 1.0);

        //vec3 lumcoeff = vec3(0.299, 0.587, 0.114);
        //float lum = dot(color.rgb, lumcoeff) * lumInfluence;

        //occlusion = lum + ((1.0 - lum) * occlusion);

        postProcess.color.r = occlusion;
        //postProcess.color.r = -depth - 4.5;
    }
}
