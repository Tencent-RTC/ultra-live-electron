material {
    name : unity_hbao,
    parameters : [
        {
            type : sampler2d,
            name : depth,
            precision: high
        },
        {
            type : sampler2d,
            name : noise,
            precision: medium
        },
        {
            type : float4,
            name : resolution
        },
        {
            type : int,
            name : DIRECTIONS
        },
        {
            type : int,
            name : STEPS
        },
        {
            type : float,
            name : _MaxDistance
        },
        {
            type : float,
            name : _Radius
        },
        {
            type : float,
            name : _MaxRadiusPixels
        },
        {
            type : float,
            name : _AOmultiplier
        },
        {
            type : float,
            name : _DistanceFalloff
        },
        {
            type : float,
            name : _AngleBias
        },
        {
            type : float,
            name : _NegInvRadius2
        },
        {
            type : float,
            name : _Intensity
        }
    ],
    variables : [
         vertex
    ],
    domain : postprocess,
    depthWrite : false,
    depthCulling : true
}

vertex {
    void postProcessVertex(inout PostProcessVertexInputs postProcess) {
        postProcess.vertex.xy = postProcess.normalizedUV;
    }
}

fragment {

    highp float linearizeDepth(highp float depth) {
        // Our far plane is at infinity, which causes a division by zero below, which in turn
        // causes some issues on some GPU. We workaround it by replacing "infinity" by the closest
        // value representable in  a 24 bit depth buffer.
        const float preventDiv0 = -1.0 / 16777216.0;
        highp mat4 projection = getClipFromViewMatrix();
        highp float z = depth * 2.0 - 1.0; // depth in clip space
        return -projection[3].z / min(preventDiv0, z + projection[2].z);
    }

    highp float sampleDepthLinear(const vec2 uv) {
        return linearizeDepth(texture(materialParams_depth, uv, 0.0).r);
    }

    highp vec3 computeViewSpacePositionFromDepth(vec2 p, highp float linearDepth) {
        p = p * 2.0 - 1.0; // to clip space
        highp mat4 invProjection = getViewFromClipMatrix();
        p.x *= invProjection[0].x;
        p.y *= invProjection[1].y;
        return vec3(p * -linearDepth, linearDepth);
    }

    // compute normals using derivatives, which essentially results in half-resolution normals
    // this creates arifacts around geometry edges
    highp vec3 computeViewSpaceNormalNotNormalized(const highp vec3 position) {
        highp vec3 dpdx = dFdx(position);
        highp vec3 dpdy = dFdy(position);
        return cross(dpdx, dpdy);
    }

    // compute normals directly from the depth texture, resulting in full resolution normals
    highp vec3 computeViewSpaceNormalNotNormalized(const highp vec3 position, const vec2 uv) {
        vec2 uvdx = uv + vec2(materialParams.resolution.z, 0.0);
        vec2 uvdy = uv + vec2(0.0, materialParams.resolution.w);
        highp vec3 px = computeViewSpacePositionFromDepth(uvdx, sampleDepthLinear(uvdx));
        highp vec3 py = computeViewSpacePositionFromDepth(uvdy, sampleDepthLinear(uvdy));
        highp vec3 dpdx = px - position;
        highp vec3 dpdy = py - position;
        return cross(dpdx, dpdy);
    }

    vec3 getTrigNoise(const vec2 uv) {
        uint ix = uint(gl_FragCoord.x) & 0x3Fu;
        uint iy = uint(gl_FragCoord.y) & 0x3Fu;
        return texelFetch(materialParams_noise, ivec2(ix, iy), 0).xyz;
    }

    //const int DIRECTIONS = 3;
    //const int STEPS = 2;

    //const float _MaxDistance = 120;
    //const float _Radius = 0.5;
    //const float _MaxRadiusPixels = 64;

    //const float _AOmultiplier = 2;
    //const float _DistanceFalloff = 20;
    //const float _AngleBias = 0;
    //const float _NegInvRadius2 = -4;


    const float UNITY_PI = 3.14159265359;

    float rand(vec2 co, float2 size, bool noise)
    {
        if (noise) {
            return fract(sin(dot(co.xy, vec2(12.9898, 78.233)*3.0)) * 43758.5453);
        } else {
            return ((fract(1.0-co.s*(size.x/2.0))*0.3)+(fract(co.t*(size.y/2.0))*0.6))*2.0-1.0;
        }
    }

    vec2 rand2D(vec2 coord, float2 size, bool noise, float noiseamount)//generating noise/pattern texture for dithering
    {
        float noiseX = ((fract(1.0-coord.s*(size.x/2.0))*0.25)+(fract(coord.t*(size.y/2.0))*0.75))*2.0-1.0;
        float noiseY = ((fract(1.0-coord.s*(size.x/2.0))*0.75)+(fract(coord.t*(size.y/2.0))*0.25))*2.0-1.0;

        if (noise)
        {
            noiseX = clamp(fract(sin(dot(coord, vec2(12.9898, 78.233))) * 43758.5453), 0.0, 1.0)*2.0-1.0;
            noiseY = clamp(fract(sin(dot(coord, vec2(12.9898, 78.233)*2.0)) * 43758.5453), 0.0, 1.0)*2.0-1.0;
        }
        return vec2(noiseX, noiseY)*noiseamount;
    }

    float2 RotateDirections(float2 dir, float2 rot) {
    	return float2(dir.x * rot.x - dir.y * rot.y,
    					 dir.x * rot.y + dir.y * rot.x);
    }

    float Falloff(float distanceSquare) {
		// 1 scalar mad instruction
		return distanceSquare * materialParams._NegInvRadius2 + 1.0;
	}

	float _rsqrt(float value){
	    return 1.0 / sqrt(value);
	}

	float lerp(float a, float b, float w) {
      return a + w*(b-a);
    }

    float ComputeAO(float3 P, float3 N, float3 S) {
        float3 V = S - P;
    	float VdotV = dot(V, V);
    	float NdotV = dot(N, V) * _rsqrt(VdotV);

    	// Use saturate(x) instead of max(x,0.f) because that is faster on Kepler
    	return saturate(NdotV - materialParams._AngleBias) * saturate(Falloff(VdotV));
    }

    void postProcess(inout PostProcessInputs postProcess) {

        int DIRECTIONS = materialParams.DIRECTIONS;
        int STEPS = materialParams.STEPS;

        float _MaxDistance = materialParams._MaxDistance;
        float _Radius = materialParams._Radius;
        float _MaxRadiusPixels = materialParams._MaxRadiusPixels;

        float _AOmultiplier = materialParams._AOmultiplier;
        float _DistanceFalloff = materialParams._DistanceFalloff;
        float _AngleBias = materialParams._AngleBias;
        float _NegInvRadius2 = materialParams._NegInvRadius2;

        highp vec2 uv = variable_vertex.xy; // interpolated to pixel center
        highp float depth = sampleDepthLinear(uv);

        //vec2 texCoord = uv;

        //mat4 viewProjectionInverseMatrix  = getViewFromClipMatrix();

        float4 _ScreenParams = materialParams.resolution;
        _ScreenParams.zw += 1.0;

        vec3 P = computeViewSpacePositionFromDepth(uv, depth);

        //clip(_MaxDistance - P.z);
        //P.z取值范围(-无穷, -0.01]
        if(_MaxDistance + P.z < 0.0){
            discard;
            return;
        }

        float stepSize = min(_Radius / -P.z, _MaxRadiusPixels) / (float(STEPS) + 1.0);

        float3 rand = getTrigNoise(uv);

        float2 InvScreenParams = _ScreenParams.zw - 1.0;

        highp vec3 normalNotNormalized = computeViewSpaceNormalNotNormalized(P, uv);
        float3 N = normalize(normalNotNormalized);

		float alpha = 2.0 * UNITY_PI / float(DIRECTIONS);
		float ao = 0.0;

		for (int d = 0; d < DIRECTIONS; ++d) {
		    float angle = alpha * float(d);

            // Compute normalized 2D direction
            float cosA = cos(angle), sinA = sin(angle);

            float2 direction = RotateDirections(float2(cosA, sinA), rand.xy);

            // Jitter starting sample within the first step
            float rayPixels = (rand.z * stepSize + 1.0);

            for (int s = 0; s < STEPS; ++s) {
                float2 snappedUV = round(rayPixels * direction) * InvScreenParams + uv;
                highp float snappedDepth = sampleDepthLinear(snappedUV);
                float3 S = computeViewSpacePositionFromDepth(snappedUV, snappedDepth);

                rayPixels += stepSize;

                float contrib = ComputeAO(P, N, S);

                ao += contrib;
            }
		}

		ao *= (_AOmultiplier / float(STEPS * DIRECTIONS));

        //float fallOffStart = _MaxDistance - _DistanceFalloff;

        //ao = lerp(saturate(1.0 - ao), 1.0, saturate((-P.z - fallOffStart) / (_MaxDistance - fallOffStart)));

        ao = saturate(1.0 - ao);
        ao = saturate(pow(ao, materialParams._Intensity));
        postProcess.color.r = ao;
        //postProcess.color.r = -depth - 4.5;
    }
}
